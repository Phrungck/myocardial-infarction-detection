{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.utils.data as torchdata\n",
    "import torchvision.models as models\n",
    "import gc\n",
    "import time\n",
    "from sklearn.metrics import precision_recall_fscore_support,roc_auc_score, accuracy_score\n",
    "from sklearn.metrics import precision_score,f1_score\n",
    "import albumentations as albu\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the masked images\n",
    "\n",
    "train = np.load('fold1_class_echo_train.npy')\n",
    "valid = np.load('fold1_class_echo_valid.npy')\n",
    "test = np.load('fold1_class_echo_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reshape(-1,224,224,3).transpose(0,3,1,2)\n",
    "valid = valid.reshape(-1,224,224,3).transpose(0,3,1,2)\n",
    "test = test.reshape(-1,224,224,3).transpose(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the ground truthe labels for the segments\n",
    "\n",
    "train_labels = np.load('Fold1_echo_lab_train.npy')\n",
    "test_labels = np.load('Fold1_echo_lab_test.npy')\n",
    "valid_labels = np.load('Fold1_echo_lab_valid.npy')\n",
    "\n",
    "train_labels = train_labels#,1)\n",
    "test_labels = test_labels#,1)\n",
    "valid_labels = valid_labels#,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of albumentations transformations we used\n",
    "\n",
    "transform = [\n",
    "    albu.augmentations.Rotate(limit=90,p=0.9),\n",
    "    albu.augmentations.ElasticTransform(p=0.9),\n",
    "    albu.IAAAdditiveGaussianNoise(p=0.9),\n",
    "    albu.OneOf([\n",
    "        albu.CLAHE(p=1),\n",
    "        albu.RandomBrightness(p=1),\n",
    "        albu.RandomGamma(p=1),\n",
    "    ],p=0.9),\n",
    "    albu.OneOf([\n",
    "        albu.IAASharpen(p=1),\n",
    "        albu.Blur(blur_limit=3, p=1),\n",
    "        albu.MotionBlur(blur_limit=3, p=1),\n",
    "    ],p=0.9)\n",
    " \n",
    "    ]\n",
    "\n",
    "augment = albu.Compose(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversion to tensors and float 32\n",
    "\n",
    "train_data = torch.tensor(train, dtype=torch.float32)\n",
    "train_lab = torch.tensor(train_labels, dtype=torch.float32)\n",
    "valid_data = torch.tensor(valid, dtype=torch.float32)\n",
    "valid_lab = torch.tensor(valid_labels, dtype=torch.float32)\n",
    "test_data = torch.tensor(test, dtype=torch.float32)\n",
    "test_lab = torch.tensor(test_labels, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenating input data and labels\n",
    "\n",
    "training = []\n",
    "for i in range(len(train_data)):\n",
    "    training.append([train_data[i], train_lab[i]])\n",
    "    \n",
    "validation = []\n",
    "for i in range(len(valid_data)):\n",
    "    validation.append([valid_data[i], valid_lab[i]])\n",
    "    \n",
    "testing = []\n",
    "for i in range(len(test_data)):\n",
    "    testing.append([test_data[i], test_lab[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing to DataLoader\n",
    "train_batch = 20\n",
    "batch = 10\n",
    "\n",
    "train_dl =  DataLoader(training, batch,shuffle=True)\n",
    "valid_dl = DataLoader(validation, batch)\n",
    "test_dl = DataLoader(testing, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrapping models and loaders to gpu\n",
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing to gpu\n",
    "device = get_default_device()\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "valid_dl = DeviceDataLoader(test_dl, device)\n",
    "test_dl = DeviceDataLoader(test_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting hyperparameters\n",
    "epochs = 25\n",
    "alpha = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading resnest50 architecture\n",
    "from torchvision.models import resnet50, resnet101\n",
    "from resnest.torch import resnest50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(CNNLSTM, self).__init__()\n",
    "        self.resnest = resnet50(pretrained=True)\n",
    "        self.resnest.fc = nn.Sequential(nn.Linear(self.resnest.fc.in_features, 300))\n",
    "        self.lstm = nn.LSTM(input_size=300, hidden_size=256, num_layers=3)\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "       \n",
    "    def forward(self, x_3d):\n",
    "        hidden = None\n",
    "        for t in range(x_3d.size(1)):\n",
    "            with torch.no_grad():\n",
    "                x = self.resnest(x_3d[:, -1, :, :, :])  \n",
    "            out, hidden = self.lstm(x.unsqueeze(0), hidden)         \n",
    "\n",
    "        x = self.fc1(out[-1, :, :])\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = CNNLSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnest50(pretrained=True)\n",
    "\n",
    "#Fully connected layer\n",
    "model.fc = nn.Sequential(nn.Linear(2048, 6))#,\n",
    "                        #nn.LSTM(input_size=300, hidden_size=256, num_layers=3),\n",
    "                        #nn.Linear(256,128),\n",
    "                        #nn.Linear(128,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the results of the runs\n",
    "\n",
    "result_arr = torch.zeros((epochs,3))\n",
    "best = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Training Loss: 0.6175 Training Accuracy: 0.6823\n",
      "Epoch:  0  Validation Loss: 0.4911 Validation Accuracy: 0.7701\n",
      "Epoch:  1 Training Loss: 0.5980 Training Accuracy: 0.6927\n",
      "Epoch:  1  Validation Loss: 0.4905 Validation Accuracy: 0.7708\n",
      "Epoch:  2 Training Loss: 0.5929 Training Accuracy: 0.6914\n",
      "Epoch:  2  Validation Loss: 0.5161 Validation Accuracy: 0.7502\n",
      "Epoch:  3 Training Loss: 0.5867 Training Accuracy: 0.6977\n",
      "Epoch:  3  Validation Loss: 0.4748 Validation Accuracy: 0.7681\n",
      "Epoch:  4 Training Loss: 0.5952 Training Accuracy: 0.6900\n",
      "Epoch:  4  Validation Loss: 0.4964 Validation Accuracy: 0.7403\n",
      "Epoch:  5 Training Loss: 0.5871 Training Accuracy: 0.6965\n",
      "Epoch:  5  Validation Loss: 0.4880 Validation Accuracy: 0.7438\n",
      "Epoch:  6 Training Loss: 0.5836 Training Accuracy: 0.6963\n",
      "Epoch:  6  Validation Loss: 0.5005 Validation Accuracy: 0.7771\n",
      "Epoch:  7 Training Loss: 0.5813 Training Accuracy: 0.6993\n",
      "Epoch:  7  Validation Loss: 0.5323 Validation Accuracy: 0.7062\n",
      "Epoch:  8 Training Loss: 0.5842 Training Accuracy: 0.6953\n",
      "Epoch:  8  Validation Loss: 0.4859 Validation Accuracy: 0.7603\n",
      "Epoch:  9 Training Loss: 0.5829 Training Accuracy: 0.6936\n",
      "Epoch:  9  Validation Loss: 0.4773 Validation Accuracy: 0.7651\n",
      "Epoch:  10 Training Loss: 0.5879 Training Accuracy: 0.6922\n",
      "Epoch:  10  Validation Loss: 0.5022 Validation Accuracy: 0.7653\n",
      "Epoch:  11 Training Loss: 0.5871 Training Accuracy: 0.6916\n",
      "Epoch:  11  Validation Loss: 0.4848 Validation Accuracy: 0.7681\n",
      "Epoch:  12 Training Loss: 0.5913 Training Accuracy: 0.6917\n",
      "Epoch:  12  Validation Loss: 0.4917 Validation Accuracy: 0.7764\n",
      "Epoch:  13 Training Loss: 0.5814 Training Accuracy: 0.6939\n",
      "Epoch:  13  Validation Loss: 0.4738 Validation Accuracy: 0.7715\n",
      "Epoch:  14 Training Loss: 0.5824 Training Accuracy: 0.6948\n",
      "Epoch:  14  Validation Loss: 0.4744 Validation Accuracy: 0.8111\n",
      "Epoch:  15 Training Loss: 0.5819 Training Accuracy: 0.6942\n",
      "Epoch:  15  Validation Loss: 0.5064 Validation Accuracy: 0.7729\n",
      "Epoch:  16 Training Loss: 0.5826 Training Accuracy: 0.6919\n",
      "Epoch:  16  Validation Loss: 0.4955 Validation Accuracy: 0.7542\n",
      "Epoch:  17 Training Loss: 0.5806 Training Accuracy: 0.6947\n",
      "Epoch:  17  Validation Loss: 0.5266 Validation Accuracy: 0.7257\n",
      "Epoch:  18 Training Loss: 0.5769 Training Accuracy: 0.6944\n",
      "Epoch:  18  Validation Loss: 0.5016 Validation Accuracy: 0.7542\n",
      "Epoch:  19 Training Loss: 0.5811 Training Accuracy: 0.6943\n",
      "Epoch:  19  Validation Loss: 0.5112 Validation Accuracy: 0.7269\n",
      "Epoch:  20 Training Loss: 0.5792 Training Accuracy: 0.6950\n",
      "Epoch:  20  Validation Loss: 0.4847 Validation Accuracy: 0.7388\n",
      "Epoch:  21 Training Loss: 0.5787 Training Accuracy: 0.6981\n",
      "Epoch:  21  Validation Loss: 0.4932 Validation Accuracy: 0.7597\n",
      "Epoch:  22 Training Loss: 0.5787 Training Accuracy: 0.6990\n",
      "Epoch:  22  Validation Loss: 0.4877 Validation Accuracy: 0.7569\n",
      "Epoch:  23 Training Loss: 0.5792 Training Accuracy: 0.6972\n",
      "Epoch:  23  Validation Loss: 0.4848 Validation Accuracy: 0.7417\n",
      "Epoch:  24 Training Loss: 0.5784 Training Accuracy: 0.6974\n",
      "Epoch:  24  Validation Loss: 0.5024 Validation Accuracy: 0.7556\n",
      "Processing Time:  2586.8055531978607\n"
     ]
    }
   ],
   "source": [
    "to_device(model, device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=alpha)\n",
    "#Since this is a multi-label classification, BCE with Logits loss is used\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "loss_function = loss_function.cuda()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    val_out = torch.zeros(0).cuda()\n",
    "    model.train()\n",
    "    t_count = 0\n",
    "    t_loss = 0\n",
    "    t_acc = 0\n",
    "    \n",
    "    for data,target in train_dl:\n",
    "        arr = []\n",
    "        \n",
    "        for i in range(data.shape[0]):\n",
    "            \n",
    "            np_img = data[i].cpu().numpy()\n",
    "            np_img = np_img.transpose(1,2,0)\n",
    "            sample = augment(image=np_img.astype('uint8'))\n",
    "            img = sample['image']\n",
    "            arr.append(img)\n",
    "            \n",
    "        data = np.array(arr)\n",
    "        data = data.transpose(0,3,1,2)\n",
    "        data = torch.tensor(data, dtype=torch.float32)\n",
    "        data = data.cuda()\n",
    "        \n",
    "        #data = torch.vstack((data,data))\n",
    "        #target = torch.vstack((target,target))\n",
    "        \n",
    "        t_count += 1\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        preds = torch.sigmoid(output)\n",
    "        preds = torch.round(preds)\n",
    "\n",
    "        loss = loss_function(output, target)\n",
    "        \n",
    "        #Computing a running total of loss and accuracy\n",
    "        t_loss += loss.item()\n",
    "        acc = torch.sum(preds==target).item()/(target.shape[0]*target.shape[1])\n",
    "        t_acc += acc\n",
    "        \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_accuracy = t_acc/t_count\n",
    "    train_loss = t_loss/t_count\n",
    "    \n",
    "    print('Epoch: ', epoch, 'Training Loss: {:.4f}'.format(train_loss)\\\n",
    "          ,'Training Accuracy: {:.4f}'.format(train_accuracy))\n",
    "    \n",
    "    model.eval()\n",
    "    v_count = 0\n",
    "    v_loss = 0\n",
    "    v_acc = 0\n",
    "    val_out = torch.zeros(0).cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for val_data,val_target in valid_dl:\n",
    "            v_count += 1\n",
    "            val_output = model(val_data)\n",
    "\n",
    "            val_preds = torch.sigmoid(val_output)\n",
    "            val_preds = torch.round(val_preds)\n",
    "\n",
    "            val_out = torch.cat((val_out,val_preds),axis=0)\n",
    "\n",
    "            val_loss = loss_function(val_output, val_target)\n",
    "\n",
    "            v_loss += val_loss.item()\n",
    "            val_acc = torch.sum(val_preds==val_target).item()/(val_target.shape[0]*val_target.shape[1])\n",
    "            v_acc += val_acc\n",
    "\n",
    "        val_accuracy = v_acc/v_count\n",
    "        val_loss = v_loss/v_count\n",
    "\n",
    "        print('Epoch: ', epoch, ' Validation Loss: {:.4f}'.format(val_loss)\\\n",
    "              ,'Validation Accuracy: {:.4f}'.format(val_accuracy))\n",
    "\n",
    "        #Saving the best model\n",
    "        if val_accuracy > best:\n",
    "            best = val_accuracy\n",
    "            torch.save(model, './valclass.pth')\n",
    "    \n",
    "    #Saving the best model\n",
    "    #if train_accuracy > best:\n",
    "        #best = train_accuracy\n",
    "        #torch.save(model, './trialclass.pth')\n",
    "\n",
    "    result_arr[epoch,0] = epoch\n",
    "    result_arr[epoch,1] = train_loss\n",
    "    result_arr[epoch,2] = train_accuracy\n",
    "\n",
    "end_time = time.time()\n",
    "print('Processing Time: ',end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = torch.load('./valclass.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7566807313642757\n",
      "Scores:  (0.404, 0.3389261744966443, 0.36861313868613144, None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8674377224199288"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "t_count = 0\n",
    "t_loss = 0\n",
    "t_acc = 0\n",
    "test_out = torch.zeros(0).cuda()\n",
    "        \n",
    "with torch.no_grad():\n",
    "        \n",
    "    for test_data,test_target in test_dl:\n",
    "        t_count += 1\n",
    "        test_output = model(test_data)\n",
    "            \n",
    "        test_preds = torch.sigmoid(test_output)\n",
    "        test_preds = torch.round(test_preds)\n",
    "        \n",
    "        test_out = torch.cat((test_out,test_preds),axis=0)\n",
    "        \n",
    "true_data = test_labels.reshape(-1)\n",
    "pred_data = test_out.reshape(-1).cpu()\n",
    "\n",
    "#Accuracy scores\n",
    "score_acc = accuracy_score(true_data,pred_data)\n",
    "\n",
    "#Precision scores\n",
    "score_prf = precision_recall_fscore_support(true_data, pred_data, average='binary')\n",
    "\n",
    "print('Accuracy: ',score_acc)\n",
    "print('Scores: ',score_prf)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(true_data,pred_data).ravel()\n",
    "specificity = tn/(tn+fp)\n",
    "specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "t_count = 0\n",
    "t_loss = 0\n",
    "t_acc = 0\n",
    "test_out = torch.zeros(0).cuda()\n",
    "        \n",
    "with torch.no_grad():\n",
    "        \n",
    "    for test_data,test_target in test_dl:\n",
    "        t_count += 1\n",
    "        test_output = best_model(test_data)\n",
    "            \n",
    "        test_preds = torch.sigmoid(test_output)\n",
    "        test_preds = torch.round(test_preds)\n",
    "        \n",
    "        test_out = torch.cat((test_out,test_preds),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_data = test_labels.reshape(-1)\n",
    "pred_data = test_out.reshape(-1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy scores\n",
    "score_acc = accuracy_score(true_data,pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision scores\n",
    "score_prf = precision_recall_fscore_support(true_data, pred_data, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8129395218002813\n",
      "Scores:  (0.6095890410958904, 0.2986577181208054, 0.4009009009009009, None)\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ',score_acc)\n",
    "print('Scores: ',score_prf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.949288256227758"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(true_data,pred_data).ravel()\n",
    "specificity = tn/(tn+fp)\n",
    "specificity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
